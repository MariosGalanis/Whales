{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import and Convert images\n",
    "\n",
    "data = []\n",
    "labels = pd.read_csv(\"C:/Users/galan/Desktop/Stanford Classes/Quarter 9/Deep Learning/Project/train.csv\")\n",
    "labels[\"Id\"] = labels[\"Id\"].astype('category')\n",
    "labels[\"Id_cat\"] = labels[\"Id\"].cat.codes                                              # Convert Id's to Numbers\n",
    "id_label = labels[labels.columns[2]].tolist()                                          # Create a list with whale Id's\n",
    "path = \"C:/Users/galan/Desktop/Stanford Classes/Quarter 9/Deep Learning/Project/train\" # Folder with Whale Images\n",
    "img_size = 200                                                                         # Size that we will use to reshape images\n",
    "\n",
    "def create_data():\n",
    "    ii = 0\n",
    "    for img in os.listdir(path):\n",
    "        img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)   # import each image and convert to grayscale\n",
    "        new_array = cv2.resize(img_array, (img_size, img_size))                # convert images to desired size\n",
    "        data.append([new_array, id_label[ii]])                                 # append images and Id labels to data list\n",
    "        ii += 1 \n",
    "        \n",
    "create_data()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data for Training and Test Sets\n",
    "\n",
    "random.shuffle(data)   # Shuffle Data\n",
    "percentage = 0.8       # Decide percentage of Training set\n",
    "\n",
    "train_number = int(round(percentage*len(data)))\n",
    "train_data = data[0:train_number]\n",
    "test_data = data[train_number:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Training and Test Sets\n",
    "\n",
    "X_train = []\n",
    "Y_tr = []\n",
    "X_test = []\n",
    "Y_te = []\n",
    "\n",
    "for features, label in train_data:\n",
    "    X_train.append(features)\n",
    "    Y_tr.append(label)\n",
    "\n",
    "for features, label in test_data:\n",
    "    X_test.append(features)\n",
    "    Y_te.append(label)\n",
    "    \n",
    "X_train = np.array(X_train).reshape(-1,img_size,img_size,1)  # Convert to Numpy array for your NN\n",
    "X_test = np.array(X_test).reshape(-1,img_size,img_size,1)    # Convert to Numpy array for your NN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make Label Sets Numpy Arrays of ones and zeros\n",
    "\n",
    "Y_train = np.zeros((len(Y_tr), max(id_label)+1))\n",
    "for ii in range(Y_train.shape[0]):\n",
    "    Y_train[ii][Y_tr[ii]] = 1\n",
    "    \n",
    "Y_test = np.zeros((len(Y_te), max(id_label)+1))\n",
    "for ii in range(Y_test.shape[0]):\n",
    "    Y_test[ii][Y_te[ii]] = 1\n",
    "\n",
    "## Convert Unique IDs to New Whale labels    \n",
    "    \n",
    "Y = np.concatenate((Y_train, Y_test), axis=0)\n",
    "        \n",
    "Suma = np.sum(Y, axis = 0)\n",
    "for jj in range(len(Suma)):\n",
    "    if Suma[jj] < 2:\n",
    "        itemindex = np.where(Y[:,jj]==1)\n",
    "        Y[itemindex,jj] = 0\n",
    "        Y[itemindex,0] = 1\n",
    "\n",
    "## Create the final version of Training and Test Label numpy arrays        \n",
    "        \n",
    "Y_train = Y[0:train_number, :]\n",
    "Y_test = Y[train_number:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Sets into files to save time next time!\n",
    "\n",
    "pickle_out = open(\"X_train.pickle\",\"wb\")\n",
    "pickle.dump(X_train, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"Y_train.pickle\",\"wb\")\n",
    "pickle.dump(Y_train, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"X_test.pickle\",\"wb\")\n",
    "pickle.dump(X_test, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"Y_test.pickle\",\"wb\")\n",
    "pickle.dump(Y_test, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"labels.pickle\",\"wb\")\n",
    "pickle.dump(labels, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
